{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get credentials\n",
    "from IPython.utils import io\n",
    "with io.capture_output() as captured:\n",
    "    %run ../Introduction.ipynb\n",
    "    \n",
    "from datetime import datetime\n",
    "from sentenai import Sentenai\n",
    "sentenai = Sentenai(host=host, port=port)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Stream Databases\n",
    "\n",
    "Stream databases are the building block of data sets in Sentenai. A Stream database represent something as simple as a single data feed, or as complex as an entire production line on a factory floor. Data streams in a stream database are organized into a tree-like hierarchy of relationships. This hierarchy is purely organizational in nature, but splitting complex flat data sets into a hierarchical organization can have substantial performance benefits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an example of a flat dataset called \"Activity\" like you'd typically see in a relational database:\n",
    "\n",
    "| Timestamp | Location | Sensor | Temperature | Humidity\n",
    "| --- | --- | --- | --- | --- |\n",
    "| 2020-01-01T00:00:00Z | Boston | 53 | 48 | .83\n",
    "| 2020-01-01T00:00:00Z | Providence | 48 | 43 | .55\n",
    "\n",
    "\n",
    "In Sentenai you might instead arrange your dataset:\n",
    "```\n",
    "- Activity\n",
    "  - Boston\n",
    "    - 53\n",
    "      - Temperature\n",
    "      - Humidity\n",
    "  - Providence\n",
    "    - 48\n",
    "      - Temperature\n",
    "      - Humidity\n",
    "```\n",
    "\n",
    "This organization implies there are natural filters you'd want to apply:\n",
    "\n",
    "`Activity/Boston/53/Temperature` is equivalent to filtering a table on Location and Sensor id."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Managing data in a Stream Database\n",
    "\n",
    "Stream databases feature transactional data logging. Any streams within the stream graph can be updated in a single transaction, provided the update applies to the same time interval across all updated streams.\n",
    "\n",
    "So if we initialize a new database `test-2':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = sentenai.init('test-2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can update the entire database with each insertion without requiring any up-front schema declaration of stream instantiation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.log[datetime(2020, 1, 1): datetime(2020, 1, 1, 1): 'update-1'] = {\n",
    "    'Boston': {\n",
    "        '53': {\n",
    "            'Temperature': 48.0,\n",
    "            'Humidity': 0.83,\n",
    "        },\n",
    "    },\n",
    "    'Providence': {\n",
    "        '48': {\n",
    "            'Temperature': 43.0,\n",
    "            'Humidity': 0.55,\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've inserted our first update into the database's `log`, we can see for ourselves the structure using the `.graph` property of the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test-2\n",
      "├── Boston\n",
      "│   └── 53\n",
      "│       ├── Humidity\n",
      "│       └── Temperature\n",
      "└── Providence\n",
      "    └── 48\n",
      "        ├── Humidity\n",
      "        └── Temperature\n",
      "\n"
     ]
    }
   ],
   "source": [
    "db.graph.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each node in this tree is a stream of either events or values. A stream of values is just a stream of events with a value attached, so in essence every node in the tree is the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inserting bulk data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the basic pattern of insertion into the log with `[ start : (optional) end : (optional) id ]`, you can also stream large amounts of data over a single connection using Python's `with` keyword and a streaming context manager. To start up the streaming connection, type:\n",
    "```\n",
    "with db.log as log:\n",
    "```\n",
    "This creates a new streaming connection, called `log`, for us to use to insert data. This connection can actively manage asynchronous uploading and buffering data, so you can feel free to iterate over very large files without worrying about them being loaded fully into memory. Here's a basic example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "with db.log as log:\n",
    "    for i in range(50):\n",
    "        db.log[datetime(2020, 1, 1, 2, i) : : ] = {\n",
    "            'Boston': {'53': {\n",
    "                'Humidity' : random.random(),\n",
    "                'Temperature': random.random() * 100\n",
    "            }}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving an update by unique id\n",
    "\n",
    "Updates can be retrieved by id:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Boston': {'53': {'Humidity': 0.83, 'Temperature': 48.0}},\n",
       " 'Providence': {'48': {'Humidity': 0.55, 'Temperature': 43.0}}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.log['update-1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Deleting an update\n",
    "\n",
    "If an individual update has been given a unique id, it can be deleted from the log by its id:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "del db.log['update-1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'update not found.'\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(db.log['update-1'])\n",
    "except KeyError as k:\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving updates by time\n",
    "\n",
    "You can retrieve a set of updates by time slice: `db.log[ start : end : limit ]`. All arguments are optional. To retrieve all updates you can do `db.log[:]`. To get the first 5 updates, do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'start': numpy.datetime64('2020-01-01T02:00:00'), 'end': None, 'data': {'Boston': {'53': {'Humidity': 0.9294579174551353, 'Temperature': 22.32584915785809}}}}\n",
      "{'start': numpy.datetime64('2020-01-01T02:01:00'), 'end': None, 'data': {'Boston': {'53': {'Humidity': 0.6331413173773333, 'Temperature': 81.71983424155601}}}}\n",
      "{'start': numpy.datetime64('2020-01-01T02:01:00'), 'end': None, 'data': {'Boston': {'53': {'Humidity': 0.030784589936583617, 'Temperature': 96.44885425146505}}}}\n",
      "{'start': numpy.datetime64('2020-01-01T02:01:00'), 'end': None, 'data': {'Boston': {'54': {'Humidity': 55}}}}\n",
      "{'start': numpy.datetime64('2020-01-01T02:02:00'), 'end': None, 'data': {'Boston': {'53': {'Humidity': 0.3031839372221987, 'Temperature': 23.21499324972436}}}}\n"
     ]
    }
   ],
   "source": [
    "for x in db.log[ : : 5]:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Negative limit values reverse the retrieval order. To get the last five updates, you can do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'start': numpy.datetime64('2020-01-01T02:49:00'), 'end': None, 'data': {'Boston': {'53': {'Humidity': 0.7662644674096308, 'Temperature': 93.03395578163271}}}}\n",
      "{'start': numpy.datetime64('2020-01-01T02:49:00'), 'end': None, 'data': {'Boston': {'53': {'Humidity': 0.5353517813206717, 'Temperature': 8.141972824783416}}}}\n",
      "{'start': numpy.datetime64('2020-01-01T02:48:00'), 'end': None, 'data': {'Boston': {'53': {'Humidity': 0.04041089532843878, 'Temperature': 94.67279770679082}}}}\n",
      "{'start': numpy.datetime64('2020-01-01T02:48:00'), 'end': None, 'data': {'Boston': {'53': {'Humidity': 0.10329406728415713, 'Temperature': 77.18615457054389}}}}\n",
      "{'start': numpy.datetime64('2020-01-01T02:47:00'), 'end': None, 'data': {'Boston': {'53': {'Humidity': 0.16096466815504118, 'Temperature': 90.58414373050245}}}}\n"
     ]
    }
   ],
   "source": [
    "for x in db.log[ : : -5]:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Properties of a Stream Database\n",
    "\n",
    "A stream database has several properties that are useful when writing programs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test-2\n"
     ]
    }
   ],
   "source": [
    "# Name\n",
    "print(db.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.datetime64('1970-01-01T00:00:00')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Origin\n",
    "db.origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of updates\n",
    "len(db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing Streams in a Stream Database\n",
    "\n",
    "So far we've seen how to manage data in a stream database, but we haven't yet seen how to work with that data.\n",
    "\n",
    "Stream databases are dict-like objects, so we can access streams in the same way we would access a value in a dict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test-2/Boston\n",
      "test-2/Providence\n"
     ]
    }
   ],
   "source": [
    "for key in db:\n",
    "    print(db[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.keys()` and `.items()` methods are also supported."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For paths that are multiple levels deep you can access them one of two ways:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test-2/Boston/43\n"
     ]
    }
   ],
   "source": [
    "print(db['Boston']['43'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test-2/Boston/43\n"
     ]
    }
   ],
   "source": [
    "print(db['Boston', '43'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These ways are entirely equivalent, but one may be preferable over the other depending on the situation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Next chapter: Streams](Streams.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
